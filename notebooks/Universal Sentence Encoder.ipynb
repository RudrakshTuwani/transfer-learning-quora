{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from fastai.text import *\n",
    "from src.dataloader import DatasetStream\n",
    "from src.models import ArCosModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to download USE embeddings: \n",
    "[Train](https://drive.google.com/file/d/1g2izNAlAnszU_PNALYQJWUqHWoBCmfM9/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path containing USE embeddings\n",
    "DATA=Path('../data/universal-sentence-encoder/')\n",
    "\n",
    "# Config\n",
    "bs=48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of large memory requirements of the array, we will use memory mapped\n",
    "# numpy arrays.\n",
    "\n",
    "qnemb = np.load(str(DATA/'qnemb.npy'), mmap_mode='r').astype(np.float32)\n",
    "qnlabels = np.load(str(DATA/'qnlabels.npy'), mmap_mode='r').astype(np.float32)\n",
    "\n",
    "# Get CV idxs\n",
    "total = qnlabels.shape[0]\n",
    "idxs = np.array([i for i in range(total)])\n",
    "trn_idxs, val_idxs = train_test_split(idxs, test_size=0.1, random_state=0)\n",
    "\n",
    "# Make Datasets\n",
    "trn_ds = DatasetStream(qnemb, qnlabels, trn_idxs)\n",
    "val_ds = DatasetStream(qnemb, qnlabels, val_idxs)\n",
    "\n",
    "# Make Dataloaders\n",
    "trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False)\n",
    "\n",
    "# Create fast.ai Model Data Object\n",
    "md = ModelData('.', trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 2, 512]) torch.Size([48])\n"
     ]
    }
   ],
   "source": [
    "# View a sample\n",
    "x, y = next(iter(md.trn_dl))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The middle two dimensions correspond to different embedding for the question pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Baseline Model - ArCos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the distance formulation used in the original \"Universal Sentence Encoder\" paper for judging similarity between pairs of sentences, as baseline we first compute the cosine similarity between vectors of the question pairs and then apply arccos to convert it into an angular distance. We then map the distances to probabilities using a Logistic Regression Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n",
      "Completed 2001 batches\n",
      "Completed 4001 batches\n",
      "Completed 6001 batches\n",
      "Completed all batches!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  1.0min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n",
      "Completed all batches!\n",
      "Accuracy:  0.7180489252764105\n",
      "Negative Log loss:  0.537030617229838\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.68      0.75     25520\n",
      "        1.0       0.59      0.78      0.67     14909\n",
      "\n",
      "avg / total       0.75      0.72      0.72     40429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marcos = ArCosModel(trn_dl, val_dl, class_weight=\"balanced\")\n",
    "marcos.fit()\n",
    "marcos.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feedforward Neural Net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
