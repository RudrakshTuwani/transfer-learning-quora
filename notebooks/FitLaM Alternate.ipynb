{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8-27TmRu9k4-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MlrMjRG69k52"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'drive' in os.listdir():\n",
    "    COLAB=True\n",
    "    os.chdir('drive/dl-projects/transfer-learning-quora/notebooks/')\n",
    "else:\n",
    "    COLAB=False\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yGt-W2Kg9k6W"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.text import *\n",
    "from pathlib import Path\n",
    "import dill as pickle\n",
    "from src.dataloader import PairedDataset, PairedEmbedDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "DATA = Path('../data/')\n",
    "LM = DATA/'language-model/'\n",
    "CLS = DATA/'classifier/'\n",
    "TMP = DATA/'tmp'\n",
    "\n",
    "if COLAB:  \n",
    "    WT = Path('/content/models/wt103/')\n",
    "else:\n",
    "    WT = DATA/'wt/models/wt103/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R78ZXI_G9k64"
   },
   "source": [
    "### 1. Load vocabulary and classifier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9Sx-PINR9k7K"
   },
   "outputs": [],
   "source": [
    "# Tokenized text\n",
    "qntok = np.load(CLS/'cls_trn.npy')\n",
    "qnlabels = np.load(CLS/'cls_trn_lbl.npy').astype(np.float32)\n",
    "\n",
    "# Split into training and validation sets.\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.1, random_state=0)\n",
    "trn_idx, val_idx = next(iter(sss.split(qntok, qnlabels)))\n",
    "\n",
    "trn, trn_lbl = qntok[trn_idx], qnlabels[trn_idx]\n",
    "val, val_lbl = qntok[val_idx], qnlabels[val_idx]\n",
    "\n",
    "# Load vocab\n",
    "itos = pickle.load((DATA/'itos.p').open('rb'))\n",
    "stoi = pickle.load((DATA/'stoi.p').open('rb'))\n",
    "vs = len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make DataSets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_trn, q2_trn = trn[:, 0], trn[:, 1]\n",
    "q1_val, q2_val = val[:, 0], val[:, 1]\n",
    "lbl_trn = trn_lbl\n",
    "lbl_val = val_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz=400\n",
    "vs=len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, X, y): self.x1,self.x2,self.y = X[0],X[1],y\n",
    "    def __getitem__(self, idx): return A(self.x1[idx], self.x2[idx], (T(self.y[idx]).float()))\n",
    "    def __len__(self): return len(self.x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = PairDataset(X=[q1_trn,q2_trn],y=(lbl_trn).T)\n",
    "val_ds = PairDataset(X=[q1_val,q2_val],y=(lbl_val).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   4,  421,   12,  154,  512,   10,  340,   50, 1845,  217,  699,  528,    2]),\n",
       " array([   4,  421,   12,    0,   10,  340,   50, 1845,  217,  699,  528,    2]),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds.__getitem__(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False) #, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False) #, sampler=val_samp)\n",
    "md = ModelData(TMP, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.Size([37, 170]), torch.Size([51, 170]), torch.Size([170, 1])),\n",
       " (torch.Size([63, 170]), torch.Size([37, 170]), torch.Size([170, 1])),\n",
       " (torch.Size([35, 170]), torch.Size([47, 170]), torch.Size([170, 1])),\n",
       " (torch.Size([36, 170]), torch.Size([39, 170]), torch.Size([170, 1])),\n",
       " (torch.Size([35, 170]), torch.Size([35, 170]), torch.Size([170, 1]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x1),len(x2),len(y)) for x1,x2,y in its]\n",
    "[((x1.shape),(x2.shape),(y.shape)) for x1,x2,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 20,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairBatchRNN(RNN_Encoder):\n",
    "    def __init__(self, bptt, max_seq, *args, **kwargs):\n",
    "        self.max_seq,self.bptt = max_seq,bptt\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def concat(self, arrs):\n",
    "        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n",
    "\n",
    "    def forward(self, input):\n",
    "        #print (input[0].shape)\n",
    "        sl,bs = input[0].size()\n",
    "        for l in self.hidden:\n",
    "            for h in l: h.data.zero_()\n",
    "        raw_outputs0, raw_outputs1, outputs0, outputs1 = [],[],[],[]\n",
    "        r0, o0 = super().forward(input[0])\n",
    "        r1, o1 = super().forward(input[1])\n",
    "        raw_outputs0.append(r0)\n",
    "        raw_outputs1.append(r1)\n",
    "        outputs0.append(o0)\n",
    "        outputs1.append(o1)\n",
    "        return self.concat(raw_outputs0), self.concat(raw_outputs1), self.concat(outputs0), self.concat(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearComparator(nn.Module):\n",
    "    initrange=0.1\n",
    "    def __init__(self, n_out, nhid, dropout, tie_encoder=None):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(nhid, 200, bias=False)\n",
    "        self.decoder2 = nn.Linear(200, 50, bias=False)\n",
    "        self.decoder3 = nn.Linear(100, 1, bias=False)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.decoder2.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.decoder3.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dropout = LockedDropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(200)\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs0, raw_outputs1, outputs0, outputs1 = input\n",
    "        output0 = self.dropout(outputs0[-1])\n",
    "        output1 = self.dropout(outputs1[-1])\n",
    "        \n",
    "        decoded0 = self.decoder(output0[-1].view(output0.size(1), output0.size(2)))\n",
    "        decoded1 = self.decoder(output1[-1].view(output1.size(1), output1.size(2)))\n",
    "        result0 = F.relu(decoded0.view(decoded0.size(1),-1))\n",
    "        result1 = F.relu(decoded1.view(decoded1.size(1),-1))\n",
    "        \n",
    "        result0 = F.relu(self.decoder2(self.bn(result0.view(result0.size(1),-1))))\n",
    "        result1 = F.relu(self.decoder2(self.bn(result1.view(result1.size(1),-1))))\n",
    "        \n",
    "        result0 = self.decoder3(torch.cat((result0,result1),1))\n",
    "        return result0, raw_outputs1, outputs1\n",
    "    \n",
    "class MultiSequentialRNN(SequentialRNN):\n",
    "    def forward(self, *input):\n",
    "        return super().forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to clean-up unwanted parameters\n",
    "def get_rnn_comparator(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n",
    "                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n",
    "    rnn_enc = PairBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n",
    "                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n",
    "    return MultiSequentialRNN(rnn_enc, LinearComparator(n_tok, emb_sz, dropout=0.2, tie_encoder=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to clean-up unwanted parameters\n",
    "m = get_rnn_comparator(bptt, 20*70, 0, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, 0], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "#learn.crit=binary_loss_crit\n",
    "learn.crit=nn.BCEWithLogitsLoss()\n",
    "learn.clip=.25\n",
    "learn.metrics = [accuracy_thresh(0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find(start_lr=lrs*5, end_lr=lrs*50, linear=False)\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5db55a71d24386a4b94abcbce403a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: ', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   <lambda>                      \n",
      "    0      0.640731   0.639699   0.632123  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.6397]), 0.6321229759531021]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs/10, 1, wds=wd, cycle_len=1, use_clr=(32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13401296c0c441af84a8737ceafe45d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: ', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2141 [00:01<46:45,  1.31s/it, loss=0.687]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244507981/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-34cad1dc4e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/fastai-0.6-py3.6.egg/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/fastai-0.6-py3.6.egg/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/fastai-0.6-py3.6.egg/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/fastai-0.6-py3.6.egg/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_backward\u001b[0;34m(self, gradients, retain_variables)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *gradients)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mnested_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_None_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mbackward_extended\u001b[0;34m(self, grad_output, grad_hy)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mgrad_hy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             grad_hx)\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fa/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mbackward_grad\u001b[0;34m(fn, input, hx, weight, output, grad_output, grad_hy, grad_input, grad_hx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mworkspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         check_error(cudnn.lib.cudnnRNNBackwardData(\n\u001b[1;32m    377\u001b[0m             \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244507981/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return A(self.x[i, 0], (self.x[i, 1]), self.y[i])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets and dataloaders\n",
    "trn_ds = PairedDataset(trn, trn_lbl)\n",
    "val_ds = PairedDataset(val, val_lbl)\n",
    "\n",
    "# transpose_y is currently a hack to transpose the second question as well. Submit PR to fastai!\n",
    "trn_samp = SortishSampler(trn_ds, key=lambda x: trn_ds[x][0].shape[0], bs=bs)\n",
    "val_samp = SortSampler(val_ds, key=lambda x: trn_ds[x][0].shape[0])\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, bs, num_workers=1, pad_idx=1, transpose=True, \n",
    "                    transpose_y=True, pre_pad=True, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, num_workers=1, pad_idx=1, transpose=True, \n",
    "                    transpose_y=True, pre_pad=True, sampler=val_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,y = next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('_pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ lately , most of the inspiring success stories carry a certain trend - the neglect for proper / formal education . is this something worth sharing simply because most millionaires and billionaires nowadays are uneducated ? does this mean formal education is not necessary ?',\n",
       " '_pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ are there nowadays scientists without formal education ( autodidacts ) ? is it possible to do scientific research without following a formal education ?')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=3\n",
    "' '.join([itos[i] for i in x1[:, j]]), ' '.join([itos[i] for i in x2[:, j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k90y-MFP9k8M"
   },
   "source": [
    "### 2. Load End-to-End Similarity Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0My038RuJzZ0"
   },
   "outputs": [],
   "source": [
    "class MultiTwoBatchRNN(MultiBatchRNN):\n",
    "    def __init__(self, bptt, max_seq, *args, **kwargs):\n",
    "        super().__init__(bptt, max_seq, *args, **kwargs)\n",
    "        super().reset()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        raw_outputs1, outputs1 = super().forward(input[0])\n",
    "        raw_outputs2, outputs2 = super().forward(input[1])\n",
    "\n",
    "        return raw_outputs1, outputs1, raw_outputs2, outputs2 \n",
    "\n",
    "\n",
    "class PoolingDiffLinearClassifier(PoolingLinearClassifier):\n",
    "#     def get_final_embedding(self, outputs):\n",
    "#         output = outputs[-1]\n",
    "#         sl, bs, _ = output.size()\n",
    "#         avgpool = self.pool(output, bs, False)\n",
    "#         mxpool = self.pool(output, bs, True)\n",
    "\n",
    "#         return torch.cat([output[-1], mxpool, avgpool], 1)\n",
    "#         return output[-1]\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        raw_outputs1, outputs1, raw_outputs2, outputs2 = inp\n",
    "#         x1 = self.get_final_embedding(outputs1)\n",
    "#         x2 = self.get_final_embedding(outputs2)\n",
    "        x1, x2 = outputs1[-1][-1], outputs2[-1][-1]\n",
    "        x = (x1 - x2).abs()\n",
    "\n",
    "        for l in self.layers:\n",
    "            l_x = l(x)\n",
    "            x = F.relu(l_x)\n",
    "            \n",
    "        return l_x.view(-1)\n",
    "\n",
    "\n",
    "class MultiSequentialRNN(SequentialRNN):\n",
    "    def forward(self, *input):\n",
    "        super().forward(input)\n",
    "\n",
    "    \n",
    "def get_question_siml_model(bptt, max_seq, n_tok, emb_sz, n_hid, nlayers, pad_token, layers, \n",
    "                            drops, bidir=False, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n",
    "                           \n",
    "    birnn_enc = MultiTwoBatchRNN(bptt, max_seq, n_tok, emb_sz=emb_sz, nhid=n_hid, nlayers=nlayers, \n",
    "                                 pad_token=pad_token, bidir=bidir,\n",
    "                                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n",
    "    \n",
    "    sim_net = PoolingDiffLinearClassifier(layers, drops)\n",
    "    \n",
    "    return MultiSequentialRNN(birnn_enc, sim_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5vpgqOhs9k8Y"
   },
   "outputs": [],
   "source": [
    "# Model config\n",
    "bptt = 70\n",
    "pad_tok = 1\n",
    "em_sz, nh, nl = 400, 1150, 3\n",
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5\n",
    "\n",
    "\n",
    "# Make model data\n",
    "md = ModelData(TMP, trn_dl, val_dl)\n",
    "\n",
    "# Similarity net\n",
    "simnet = get_question_siml_model(bptt, 20*70, vs, em_sz, nh, nlayers=nl, \n",
    "                                 pad_token=1, layers=[em_sz*1, 200, 50, 1], \n",
    "                                 drops=[dps[4], 0.15, 0.1], dropouti=dps[0],\n",
    "                                 wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "learn = RNN_Learner(md, TextModel(to_gpu(simnet)), crit=F.binary_cross_entropy_with_logits, \n",
    "                    opt_fn=optim.Adam, metrics=[accuracy_thresh(0.5)])\n",
    "\n",
    "learn.load_encoder('lm1_enc')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8KqQ0JsYTO5"
   },
   "source": [
    "### 3. Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "EKAEk_6dYb1x"
   },
   "source": [
    "#### Only head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8078
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1566000,
     "status": "ok",
     "timestamp": 1525584769020,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": -330
    },
    "hidden": true,
    "id": "BVPI9udaYbHn",
    "outputId": "6bf1ab59-857d-4b8f-bbbb-377f1556cb02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d570da42ffa48bc992b4d838c108db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: ', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 4660/7581 [23:32<08:32,  5.70it/s, loss=0.647]"
     ]
    }
   ],
   "source": [
    "wd=1e-7\n",
    "learn.lr_find(1e-5, 5, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1697,
     "status": "ok",
     "timestamp": 1525584770748,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": -330
    },
    "hidden": true,
    "id": "g_t0M3Fl20Fp",
    "outputId": "cb892db7-c496-4d66-f8fe-250b75c9a696"
   },
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 10509
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1966856,
     "status": "ok",
     "timestamp": 1525587260625,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": -330
    },
    "hidden": true,
    "id": "JfwQ1M9h3Pzn",
    "outputId": "c02ebd56-3ab0-463e-f728-7aaccba8cc22"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3edce6f5cfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wd' is not defined"
     ]
    }
   ],
   "source": [
    "learn.fit(1e-5, 1, cycle_len=1, wds=wd, use_clr=(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24287,
     "status": "ok",
     "timestamp": 1525587284952,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": -330
    },
    "hidden": true,
    "id": "PEfWkI2k-fxz",
    "outputId": "02417680-6cc6-4a9b-dde1-20730dc28c68"
   },
   "outputs": [],
   "source": [
    "learn.save('clas_lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4121,
     "status": "ok",
     "timestamp": 1525587289093,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": -330
    },
    "hidden": true,
    "id": "ShsWcw8Q-clL",
    "outputId": "51352286-de64-4273-d1b3-bf993d7ecec9"
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rdgtbqbwdr5"
   },
   "source": [
    "#### End-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wjsEOmBiKiQc"
   },
   "outputs": [],
   "source": [
    "# learn.load('clas_lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BnXFZQUI9k9g"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.clip=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 11516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3554390,
     "status": "ok",
     "timestamp": 1525592431452,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": 420
    },
    "id": "OwZTCkE39k-K",
    "outputId": "1aa3b412-95e3-45a4-994f-baede788a2bd"
   },
   "outputs": [],
   "source": [
    "wd=1e-9\n",
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])\n",
    "\n",
    "# learn.lr_find(lrs/1000, 5, wds=wd)\n",
    "# learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1882,
     "status": "ok",
     "timestamp": 1525592433788,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": 420
    },
    "id": "ozej5jH49k-6",
    "outputId": "d086713a-ea7d-4bf3-e6bf-49e4973a4422"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 49907
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10023598,
     "status": "error",
     "timestamp": 1525603600494,
     "user": {
      "displayName": "Rudraksh Tuwani",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109907361324191135545"
     },
     "user_tz": 420
    },
    "id": "oBuQesOV9k_k",
    "outputId": "32503339-68c6-48cf-fd46-ae4358720cac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f5e939a680474f89890d902bd62a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: ', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1      0.59468    0.588937   0.63305                         \n",
      " 86%|████████▌ | 6533/7581 [1:19:35<12:43,  1.37it/s, loss=0.584]"
     ]
    }
   ],
   "source": [
    "learn.fit(5e-3, 1, cycle_len=8, wds=wd, use_clr=(30, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zP8ICvDd9lAO",
    "outputId": "735168ce-cd17-4b3c-ac11-b6b8d1b79c12"
   },
   "outputs": [],
   "source": [
    "nn_evaluate(md.val_dl, learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k8albg-N9lA2",
    "outputId": "84df9d4c-1c33-4710-c066-08c014ca4e01"
   },
   "outputs": [],
   "source": [
    "learn.lr_find(1e-9, 2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Flnu1erU9lBQ",
    "outputId": "0790ffb7-cdd0-46a9-85a1-ef98f1463be2"
   },
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "FitLaM Finetuning.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "fa",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
