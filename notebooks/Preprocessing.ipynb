{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "from fastai.text import *\n",
    "import dill as pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set paths\n",
    "DATA = Path('../data/') \n",
    "LM = DATA/'language-model/'\n",
    "CLS = DATA/'classifier/' \n",
    "TMP = DATA/'tmp/'\n",
    "\n",
    "# Make directories if don't exist\n",
    "LM.mkdir(exist_ok=True)\n",
    "CLS.mkdir(exist_ok=True)\n",
    "TMP.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  is_duplicate  qid1  qid2  \\\n",
       "0  0.0           0.0   1.0   2.0   \n",
       "1  1.0           0.0   3.0   4.0   \n",
       "2  2.0           0.0   5.0   6.0   \n",
       "3  3.0           0.0   7.0   8.0   \n",
       "4  4.0           0.0   9.0  10.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  test_id  \n",
       "0  What is the step by step guide to invest in sh...      NaN  \n",
       "1  What would happen if the Indian government sto...      NaN  \n",
       "2  How can Internet speed be increased by hacking...      NaN  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...      NaN  \n",
       "4            Which fish would survive in salt water?      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([\n",
    "    pd.read_csv('../data/kaggle-dataset/train.csv', encoding='utf-8').fillna(''),\n",
    "    pd.read_csv('../data/kaggle-dataset/test.csv', encoding='utf-8').fillna('')\n",
    "])\n",
    "\n",
    "trn_idx = np.array(data.dropna(subset=['id']).index)\n",
    "tst_idx = np.array(data.dropna(subset=['test_id']).index)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixup(x):\n",
    "    \"\"\" Cleans input text. \"\"\"\n",
    "\n",
    "    #x = BeautifulSoup(x, \"lxml\").get_text()\n",
    "    x = unidecode(x)\n",
    "    \n",
    "    if not x: \n",
    "        x = ' '\n",
    "        \n",
    "    return x\n",
    "\n",
    "data['question1'] = data['question1'].apply(fixup).values.astype(str)\n",
    "data['question2'] = data['question2'].apply(fixup).values.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokq1 = Tokenizer().proc_all_mp(partition_by_cores(data.question1.as_matrix()))\n",
    "tokq2 = Tokenizer().proc_all_mp(partition_by_cores(data.question2.as_matrix()))\n",
    "\n",
    "labels = data['is_duplicate'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Make vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab config\n",
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all tokens\n",
    "all_toks = [tok for toklst in tokq1 for tok in toklst] +\\\n",
    "           [tok for toklst in tokq2 for tok in toklst]\n",
    "\n",
    "# Make mapping from integer to string\n",
    "itos = [tok for tok, count in collections.Counter(all_toks).most_common(max_vocab)\n",
    "        if count > min_freq]\n",
    "itos.insert(0, '_unk_')\n",
    "itos.insert(1, '_pad_')\n",
    "\n",
    "# Make mapping from string to integer\n",
    "stoi = collections.defaultdict(lambda: 0, {tok: i for i, tok in enumerate(itos)} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocabulary\n",
    "pickle.dump(itos, (DATA/'itos.p').open('wb'))\n",
    "pickle.dump(stoi, (DATA/'stoi.p').open('wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map token strings to vocab ids.\n",
    "tokid_q1 = np.array([[stoi[i] for i in toklst] for toklst in tokq1])\n",
    "tokid_q2 = np.array([[stoi[i] for i in toklst] for toklst in tokq2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model.\n",
    "lm = np.concatenate([tokid_q1, tokid_q2])\n",
    "\n",
    "# Split into training and validation sets\n",
    "lm_trn, lm_val = train_test_split(lm, test_size=0.1, random_state=0)\n",
    "\n",
    "# Save to disk\n",
    "np.save(LM/'lm_trn.npy', lm_trn)\n",
    "np.save(LM/'lm_val.npy', lm_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "cls = np.concatenate([tokid_q1[None], tokid_q2[None]]).T\n",
    "\n",
    "# Get train and test sets\n",
    "cls_trn = cls[trn_idx]\n",
    "cls_tst = cls[tst_idx]\n",
    "\n",
    "# Save to disk\n",
    "np.save(CLS/'cls_tst.npy', cls_tst)\n",
    "np.save(CLS/'cls_trn.npy', cls_trn)\n",
    "np.save(CLS/'cls_trn_lbl.npy', label[trn_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa",
   "language": "python",
   "name": "fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
